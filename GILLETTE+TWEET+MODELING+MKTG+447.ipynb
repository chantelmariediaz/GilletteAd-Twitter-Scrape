{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"gilettesent4.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbasol Once Showed Gillette How To Make a Co...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoycottGillette</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeetBarbasol arbasol Once Showed Gillette How ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BoycottGillette MeetBarbasol destinyisbright C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MeetBarbasol MeetBarbasol Barbasol Once Showed...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets     Label\n",
       "0  Barbasol Once Showed Gillette How To Make a Co...  Negative\n",
       "1                                    BoycottGillette  Negative\n",
       "2  MeetBarbasol arbasol Once Showed Gillette How ...  Negative\n",
       "3  BoycottGillette MeetBarbasol destinyisbright C...  Negative\n",
       "4  MeetBarbasol MeetBarbasol Barbasol Once Showed...  Negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tweet = []\n",
    "Labels = []\n",
    "\n",
    "for row in df1[\"Tweets\"]:\n",
    "    #tokenize words\n",
    "    words = word_tokenize(row)\n",
    "    #remove punctuations\n",
    "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
    "    #remove stop words\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\",\"'re\" ,\"'m\"]\n",
    "    clean_words = [word for word in clean_words if word not in english_stops]\n",
    "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
    "    #Lematise words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    Tweet.append(lemma_list)\n",
    "\n",
    "    for row in df1[\"Label\"]:\n",
    "        Labels.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = zip(Tweet, Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Data = []\n",
    "for r, v in combined:\n",
    "    bag_of_words(r)\n",
    "    Final_Data.append((bag_of_words(r),v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "print(len(Final_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance with Unigrams \n",
      "Accuracy: 0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = Final_Data[0:188], Final_Data[188:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "print(\"Naive Bayes Performance with Unigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramNB Results\n",
      "Brand Positive Precision: 0.5853658536585366\n",
      "Brand Positive Recall: 0.8888888888888888\n",
      "Brand Positive F-measure: 0.7058823529411764\n",
      "Brand Damaging Precision: 0.9166666666666666\n",
      "Brand Damaging Recall: 0.9166666666666666\n",
      "Brand Damaging F-measure: 0.7674418604651162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"UnigramNB Results\")\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    away = True           Positi : Negati =      5.2 : 1.0\n",
      "                    take = True           Positi : Negati =      4.4 : 1.0\n",
      "       thebestamancanget = True           Positi : Negati =      4.4 : 1.0\n",
      "                    real = True           Negati : Positi =      4.1 : 1.0\n",
      "                   itâs = True           Positi : Negati =      3.6 : 1.0\n",
      "                   point = True           Negati : Positi =      3.0 : 1.0\n",
      "                  people = True           Positi : Negati =      2.9 : 1.0\n",
      "                      'i = True           Positi : Negati =      2.8 : 1.0\n",
      "                     son = True           Positi : Negati =      2.8 : 1.0\n",
      "                 outrage = True           Positi : Negati =      2.8 : 1.0\n",
      "                      pa = True           Positi : Negati =      2.8 : 1.0\n",
      "                    look = True           Positi : Negati =      2.8 : 1.0\n",
      "                     day = True           Positi : Negati =      2.8 : 1.0\n",
      "                    iâm = True           Positi : Negati =      2.8 : 1.0\n",
      "                   video = True           Positi : Negati =      2.8 : 1.0\n",
      "                     fit = True           Positi : Negati =      2.8 : 1.0\n",
      "                  always = True           Positi : Negati =      2.8 : 1.0\n",
      "                      ad = True           Positi : Negati =      2.8 : 1.0\n",
      "                   thank = True           Positi : Negati =      2.7 : 1.0\n",
      "                    know = True           Negati : Positi =      2.5 : 1.0\n",
      "                    last = True           Negati : Positi =      2.5 : 1.0\n",
      "         gilletteboycott = True           Negati : Positi =      2.5 : 1.0\n",
      "              gillettead = True           Negati : Positi =      2.4 : 1.0\n",
      "             masculinity = True           Positi : Negati =      2.3 : 1.0\n",
      "                  better = True           Positi : Negati =      2.3 : 1.0\n",
      "                   think = True           Positi : Negati =      2.2 : 1.0\n",
      "                  asking = True           Positi : Negati =      2.2 : 1.0\n",
      "              commercial = True           Positi : Negati =      2.2 : 1.0\n",
      "              boycotting = True           Positi : Negati =      2.2 : 1.0\n",
      "                   viral = True           Positi : Negati =      2.0 : 1.0\n",
      "                    talk = True           Positi : Negati =      2.0 : 1.0\n",
      "                     way = True           Positi : Negati =      2.0 : 1.0\n",
      "                    body = True           Positi : Negati =      2.0 : 1.0\n",
      "                     mad = True           Positi : Negati =      2.0 : 1.0\n",
      "               beautiful = True           Positi : Negati =      2.0 : 1.0\n",
      "                   truly = True           Positi : Negati =      2.0 : 1.0\n",
      "                     see = True           Positi : Negati =      2.0 : 1.0\n",
      "                    dick = True           Positi : Negati =      2.0 : 1.0\n",
      "                    hear = True           Positi : Negati =      2.0 : 1.0\n",
      "                   metoo = True           Positi : Negati =      2.0 : 1.0\n",
      "                 replace = True           Positi : Negati =      2.0 : 1.0\n",
      "                   'this = True           Positi : Negati =      2.0 : 1.0\n",
      "                   might = True           Positi : Negati =      2.0 : 1.0\n",
      "                consumer = True           Positi : Negati =      2.0 : 1.0\n",
      "                  yâall = True           Positi : Negati =      2.0 : 1.0\n",
      "                  listen = True           Positi : Negati =      2.0 : 1.0\n",
      "                  reason = True           Positi : Negati =      2.0 : 1.0\n",
      "                    post = True           Positi : Negati =      2.0 : 1.0\n",
      "                   iâve = True           Positi : Negati =      2.0 : 1.0\n",
      "                    open = True           Positi : Negati =      2.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramDT Results\n",
      "Accuracy: 0.6883116883116883\n",
      "Brand Positive Precision: 0.5853658536585366\n",
      "Brand Positive Recall: 0.8888888888888888\n",
      "Brand Positive F-measure: 0.7058823529411764\n",
      "Brand Damaging Precision: 0.9166666666666666\n",
      "Brand Damaging Recall: 0.7407407407407407\n",
      "Brand Damaging F-measure: 0.7674418604651162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "\n",
    "print(\"UnigramDT Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(dt_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramsLogit Results\n",
      "Accuracy: 0.7142857142857143\n",
      "Brand Positive Precision: 0.5853658536585366\n",
      "Brand Positive Recall: 0.8888888888888888\n",
      "Brand Positive F-measure: 0.7058823529411764\n",
      "Brand Damaging Precision: 0.9166666666666666\n",
      "Brand Damaging Recall: 0.7540983606557377\n",
      "Brand Damaging F-measure: 0.7674418604651162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"UnigramsLogit Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(logit_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniigramSVM Recall\n",
      "Accuracy: 0.6493506493506493\n",
      "Brand Positive Precision: 0.5853658536585366\n",
      "Brand Positive Recall: 0.8888888888888888\n",
      "Brand Positive F-measure: 0.7058823529411764\n",
      "Brand Damaging Precision: 0.9166666666666666\n",
      "Brand Damaging Recall: 0.9166666666666666\n",
      "Brand Damaging F-measure: 0.7674418604651162\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"UniigramSVM Recall\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(SVM_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = zip(Tweet,Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)  \n",
    "    bigrams = bigram_finder.nbest(score_fn, n)  \n",
    "    return bag_of_words(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Data2 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_bigrams_words(z)\n",
    "    Final_Data2.append((bag_of_bigrams_words(z),e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "Naive Bayes Performance with Unigrams \n",
      "Accuracy: 0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(Final_Data2)\n",
    "print(len(Final_Data2))\n",
    "\n",
    "train_set, test_set = Final_Data2[0:218], Final_Data2[218:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Unigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "      ('gillette', 'ad') = True           Positi : Negati =      4.9 : 1.0\n",
      "('gillette', 'commercial') = True           Positi : Negati =      4.3 : 1.0\n",
      "('boycotting', 'gillette') = True           Positi : Negati =      3.8 : 1.0\n",
      "           ('ad', 'men') = True           Positi : Negati =      3.8 : 1.0\n",
      " ('threatened', 'razor') = True           Positi : Negati =      3.0 : 1.0\n",
      "         ('real', 'men') = True           Negati : Positi =      2.9 : 1.0\n",
      "     ('thing', 'offend') = True           Positi : Negati =      2.1 : 1.0\n",
      "    ('razor', 'company') = True           Positi : Negati =      2.1 : 1.0\n",
      "     ('buy', 'gillette') = True           Positi : Negati =      2.1 : 1.0\n",
      "('commercial', 'iâ\\x92ve') = True           Positi : Negati =      2.1 : 1.0\n",
      " ('razor', 'commerical') = True           Positi : Negati =      2.1 : 1.0\n",
      "       ('hint', 'razor') = True           Positi : Negati =      2.1 : 1.0\n",
      "   ('boy', 'gillettead') = True           Positi : Negati =      2.1 : 1.0\n",
      "    ('best', 'gillette') = True           Positi : Negati =      2.1 : 1.0\n",
      "        ('every', 'man') = True           Positi : Negati =      2.1 : 1.0\n",
      "           ('u', 'hint') = True           Positi : Negati =      2.1 : 1.0\n",
      "         ('offend', 'u') = True           Positi : Negati =      2.1 : 1.0\n",
      "('toxic', 'masculinity') = True           Positi : Negati =      1.9 : 1.0\n",
      "('gillette', 'gillettead') = True           Positi : Negati =      1.8 : 1.0\n",
      "    ('like', 'gillette') = True           Positi : Negati =      1.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigramDT Results\n",
      "Brand Positive Precision: 0.7272727272727273\n",
      "Brand Positive Recall: 0.5\n",
      "Brand Positive F-measure: 0.5925925925925926\n",
      "Brand Damaging Precision: 0.7777777777777778\n",
      "Brand Damaging Recall: 0.7777777777777778\n",
      "Brand Damaging F-measure: 0.835820895522388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"BigramDT Results\")\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigramDT Results\n",
      "Accuracy: 0.723404255319149\n",
      "Brand Positive Precision: 0.8\n",
      "Brand Positive Recall: 0.25\n",
      "Brand Positive F-measure: 0.38095238095238093\n",
      "Brand Damaging Precision: 0.7142857142857143\n",
      "Brand Damaging Recall: 0.7142857142857143\n",
      "Brand Damaging F-measure: 0.8219178082191781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print(\"BigramDT Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(dt_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigramsLogit Results\n",
      "Accuracy: 0.6808510638297872\n",
      "Brand Positive Precision: 0.8\n",
      "Brand Positive Recall: 0.25\n",
      "Brand Positive F-measure: 0.38095238095238093\n",
      "Brand Damaging Precision: 0.7142857142857143\n",
      "Brand Damaging Recall: 0.7142857142857143\n",
      "Brand Damaging F-measure: 0.8219178082191781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"BigramsLogit Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(logit_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams Recall\n",
      "Accuracy: 0.6595744680851063\n",
      "Brand Positive Precision: 0.8\n",
      "Brand Positive Recall: 0.25\n",
      "Brand Positive F-measure: 0.38095238095238093\n",
      "Brand Damaging Precision: 0.7142857142857143\n",
      "Brand Damaging Recall: 0.7142857142857143\n",
      "Brand Damaging F-measure: 0.8219178082191781\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Bigrams Recall\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(SVM_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = zip(Tweet,Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "def bag_of_trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq, n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)  \n",
    "    trigrams = trigram_finder.nbest(score_fn, n)  \n",
    "    return bag_of_words(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "Naive Bayes Performance with Trigrams \n",
      "Accuracy: 0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "Final_Data3 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_trigrams_words(z)\n",
    "    Final_Data3.append((bag_of_trigrams_words(z),e))\n",
    "\n",
    "import random\n",
    "random.shuffle(Final_Data3)\n",
    "print(len(Final_Data3))\n",
    "\n",
    "train_set, test_set = Final_Data3[0:218], Final_Data3[218:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Trigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand Positive Precision: 1.0\n",
      "Brand Positive Recall: 0.3888888888888889\n",
      "Brand Positive F-measure: 0.56\n",
      "Brand Damaging Precision: 0.725\n",
      "Brand Damaging Recall: 0.6595744680851063\n",
      "Brand Damaging F-measure: 0.8405797101449275\n"
     ]
    }
   ],
   "source": [
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "('gillette', 'ad', 'men') = True           Positi : Negati =      3.9 : 1.0\n",
      "('hint', 'razor', 'commerical') = True           Positi : Negati =      1.3 : 1.0\n",
      " ('offend', 'u', 'hint') = True           Positi : Negati =      1.3 : 1.0\n",
      "('truly', 'appreciate', 'men') = True           Positi : Negati =      1.3 : 1.0\n",
      "('thing', 'offend', 'u') = True           Positi : Negati =      1.3 : 1.0\n",
      "  ('u', 'hint', 'razor') = True           Positi : Negati =      1.3 : 1.0\n",
      "('company', 'truly', 'appreciate') = True           Positi : Negati =      1.3 : 1.0\n",
      "('commercial', 'asking', 'better') = True           Negati : Positi =      1.3 : 1.0\n",
      "('new', 'shaver', 'need') = True           Negati : Positi =      1.3 : 1.0\n",
      "('shaver', 'need', 'new') = True           Negati : Positi =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrigramDT Results\n",
      "Accuracy: 0.6170212765957447\n",
      "Brand Positive Precision: None\n",
      "Brand Positive Recall: 0.0\n",
      "Brand Positive F-measure: None\n",
      "Brand Damaging Precision: 0.6170212765957447\n",
      "Brand Damaging Recall: 0.6170212765957447\n",
      "Brand Damaging F-measure: 0.7631578947368421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print(\"TrigramDT Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(dt_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrigramsLogit Results\n",
      "Accuracy: 0.5106382978723404\n",
      "Brand Positive Precision: 0.4358974358974359\n",
      "Brand Positive Recall: 0.9444444444444444\n",
      "Brand Positive F-measure: 0.5964912280701755\n",
      "Brand Damaging Precision: 0.6170212765957447\n",
      "Brand Damaging Recall: 0.6170212765957447\n",
      "Brand Damaging F-measure: 0.7631578947368421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "    \n",
    "print(\"TrigramsLogit Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(logit_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams Results\n",
      "Accuracy: 0.6170212765957447\n",
      "Brand Positive Precision: 0.4358974358974359\n",
      "Brand Positive Recall: 0.9444444444444444\n",
      "Brand Positive F-measure: 0.5964912280701755\n",
      "Brand Damaging Precision: 0.6170212765957447\n",
      "Brand Damaging Recall: 0.6170212765957447\n",
      "Brand Damaging F-measure: 0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"Trigrams Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(SVM_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testsets['Negative'], refsets['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = zip(Tweet,Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bigrams\n",
    "\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Import Bigram metrics - we will use these to identify the top 200 bigrams\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "def trigrams_words(words, score_fn=TrigramAssocMeasures.chi_sq,\n",
    "n=200):\n",
    "    trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "    trigrams = trigram_finder.nbest(score_fn, n)\n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def bag_of_Ngrams_words(words):\n",
    "    bigramBag = bigrams_words(words)\n",
    "    \n",
    "    #The following two for loops convert tuple into string\n",
    "    for b in range(0,len(bigramBag)):\n",
    "        bigramBag[b]=' '.join(bigramBag[b])\n",
    "   \n",
    "    trigramBag = trigrams_words(words)\n",
    "    for t in range(0,len(trigramBag)):\n",
    "        trigramBag[t]=' '.join(trigramBag[t])\n",
    "\n",
    "    return bag_of_words(trigramBag + bigramBag + words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Data4 =[]\n",
    "\n",
    "for z, e in combined:\n",
    "    bag_of_Ngrams_words(z)\n",
    "    Final_Data4.append((bag_of_Ngrams_words(z),e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "Naive Bayes Performance with Ngrams \n",
      "Accuracy: 0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(Final_Data4)\n",
    "print(len(Final_Data4))\n",
    "\n",
    "train_set, test_set = Final_Data4[0:218], Final_Data4[218:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "\n",
    "refset = collections. defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance with Ngrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             gillette ad = True           Positi : Negati =      7.0 : 1.0\n",
      "                    away = True           Positi : Negati =      5.7 : 1.0\n",
      "                    love = True           Positi : Negati =      4.5 : 1.0\n",
      "     gillette commercial = True           Positi : Negati =      4.5 : 1.0\n",
      "                    tell = True           Positi : Negati =      3.9 : 1.0\n",
      "                     son = True           Positi : Negati =      3.9 : 1.0\n",
      "                      pa = True           Positi : Negati =      3.9 : 1.0\n",
      "                    iâm = True           Positi : Negati =      3.9 : 1.0\n",
      "                    take = True           Positi : Negati =      3.9 : 1.0\n",
      "                     guy = True           Positi : Negati =      3.9 : 1.0\n",
      "                   right = True           Positi : Negati =      3.9 : 1.0\n",
      "         gilletteboycott = True           Negati : Positi =      3.8 : 1.0\n",
      "                    time = True           Positi : Negati =      3.6 : 1.0\n",
      "                 thought = True           Negati : Positi =      3.3 : 1.0\n",
      "                   truly = True           Positi : Negati =      3.1 : 1.0\n",
      "                 society = True           Positi : Negati =      3.1 : 1.0\n",
      "              threatened = True           Positi : Negati =      3.1 : 1.0\n",
      "                 outrage = True           Positi : Negati =      3.1 : 1.0\n",
      "                    look = True           Positi : Negati =      3.1 : 1.0\n",
      "                    dick = True           Positi : Negati =      3.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand Positive Precision: 0.52\n",
      "Brand Positive Recall: 0.7222222222222222\n",
      "Brand Positive F-measure: 0.6046511627906977\n",
      "Brand Damaging Precision: 0.7727272727272727\n",
      "Brand Damaging Recall: 0.7727272727272727\n",
      "Brand Damaging F-measure: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Brand Positive Precision:', precision(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive Recall:', recall(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refset['Positive'], testset['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refset['Negative'], testset['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refset['Negative'], testset['Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NgramDT Results\n",
      "Accuracy: 0.6170212765957447\n",
      "Brand Positive Precision: 0.5\n",
      "Brand Positive Recall: 0.2777777777777778\n",
      "Brand Positive F-measure: 0.35714285714285715\n",
      "Brand Damaging Precision: 0.6486486486486487\n",
      "Brand Damaging Recall: 0.6486486486486487\n",
      "Brand Damaging F-measure: 0.7272727272727273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"NgramDT Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(dt_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive Recall:', recall(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refset['Positive'], testset['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refset['Negative'], testset['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refset['Negative'], testset['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NgramsLogit Recall\n",
      "Accuracy: 0.7021276595744681\n",
      "Brand Positive Precision: 0.5714285714285714\n",
      "Brand Positive Recall: 0.6666666666666666\n",
      "Brand Positive F-measure: 0.6153846153846154\n",
      "Brand Damaging Precision: 0.65\n",
      "Brand Damaging Recall: 0.65\n",
      "Brand Damaging F-measure: 0.7536231884057971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"NgramsLogit Recall\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(logit_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive Recall:', recall(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refset['Positive'], testset['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refset['Negative'], testset['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refset['Negative'], testset['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NgramsSVM Recall\n",
      "Accuracy: 0.6170212765957447\n",
      "Brand Positive Precision: 0.5714285714285714\n",
      "Brand Positive Recall: 0.6666666666666666\n",
      "Brand Positive F-measure: 0.6153846153846154\n",
      "Brand Damaging Precision: 0.6170212765957447\n",
      "Brand Damaging Recall: 0.6170212765957447\n",
      "Brand Damaging F-measure: 0.7631578947368421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SklearnClassifier(SVC(), sparse=False).train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = SVM_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"NgramsSVM Recall\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(SVM_classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive Recall:', recall(refset['Positive'], testset['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refset['Positive'], testset['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refset['Negative'], testset['Negative']))\n",
    "print('Brand Damaging Recall:', recall(testset['Negative'], refset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refset['Negative'], testset['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
