# GilletteAd-Twitter-Scrape
For my MKTG 447 Project group members and classmates to see step-by-step the data acquisition, manipulation, and part #1 of cleansing process for the controversial Gilette Ad Twitter Scrape using 2 packages, Python-Twitter and Twython. I appreciate any feedback from the community.

# Welcome to the Tutorial (and Github)!
The best way to follow is to follow-along with the code! 

To get started, download Anaconda distribution for Python 3.7. Once finished, launch Jupyter Notebook. 

You can access and upload both notebooks from Thomas and myself from this repository so you can run the code on your own. Remember to install any packages that are not available on your machine already.

Link: https://www.anaconda.com/distribution/

Lastly, Git is a version control system, and "a tool to manage source code history." Github is the service that hosts Git repositories or projects (Stack Overflow). 

Otherwise you can just follow along with this README.

# What is Text Analytics? 

Essentially, deriving insights from text, also considered unstructured data (not defined by rows and columns). To harness these insights from text into something that can be calculated, you will need to do some programming and understand some linguistic concepts.

# What is Natural Language Processing (NLP)?

"Natural language processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language" (SAS). Without this functionality, we would not be able to give sentiment scores for tweets, nor a frequency distribution from words. The Python package that utilizes statistical natural language processing is NLTK - or the Natural Language Toolkit.



